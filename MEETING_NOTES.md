- 13.10.21
    - Wie weit weg, wieviel Grad nimmt ein Pixel ein?
        - DVA Pixel to angle conversion
    - Mögliche Kombination RIM/Neural Processes → Trajektorien
    - Problemstellung: Wie kriegt man Stochastizität in RIMs?
    - Google Doc zum Sammeln von Fragen
    - IM - Objekt/Aufgaben
    - Für Feature Pre-processing möglicherweise pretrained ResNet
    - Mögliche Output-Formate: direkt Verteilung, Grids, konkreter Blickpunkt
- 20.10.21
    - Nico macht vielleicht
        - Eye-movement classification
        - Script zum Laden von eye-tracking Ergebnissen
    - Aufbauen auf vorhandenem Code macht Sinn
    - Erstes Starten mit Code-Implementierung
        - Dataloader
            - Kombination Video-Daten mit Eye-Tracking, und EM-Klassifikation
                - EM-Klassifikation von [https://michaeldorr.de/smoothpursuit/](https://michaeldorr.de/smoothpursuit/)
        - naives RIM
    - Beim Kopieren von fremden Repositories Anmerken in erster Zeile
    - Mögliche Teilarbeit: Verschiedene Datensätze standardisieren
        - PySaliency (Tübingen, Matthias)
    - Visual Angle vielleicht nicht sinnvoll?
        - Approximation
        - Saliency Maps auf Pixeln
    - Pytorch Lightning
        - Wrapper mit Parallelisierung
    - Nutzen von Issue-Funktionen in Github
        - Label "help wanted" für Nico/Heiner
    - Heiner: Ruhig mit kleinerem Datenset anfangen, um zu gucken ob das Model funktioniert
- 22.10.21 (Nico Group Talk)
    - NN-saliency: Molin et al 2015, Chang et al 2021
    - Scanpath static: Tatler et al 2017, Schwetlick et al 2020
    - Scanpath in dynamic scenes: Huang et al (2018)
    - End-to-End scanpath → my thesis
    - Nico: Not end-to-end
    - Bottom-up saliency (White et al 2019)
    - One of the most influential scanpath models of all time (Itti el at 1998)
        - saliency + inhibition of return
    - Visual sensitivity (Falk et al 1986)
    - Object-based sensitivity (Egly et al 1994)
    - Object-based selection (Nuthmann & Henderson 2010)
        - not centered around most salient point, but centered around center of object
    - Central fixation bias (Tatler 2007)
        - observers tend to look at center of screen
    - Needed to discard videos where object tracking is not reliable
    - record eye tracking for UVO dataset (object masks given)
        - Test ObjectDDM
    - PixelDDM
        - Inhibition around previously fixated point
    - decomposition of scanpaths Linka & de Haas 2021
        - detections
        - inspections
        - revisits
        - background
        
        → could be checked if there are neural differences in fMRI/EEG
        
    - neurolib (Cakan et al 2021)
        - Python framework for brain modeling
    - Database construction with full control over scenes & tasks
        - Miniature railway scene
- 27.10.21
    - Bumblebee-Video kürzer (und "blöder")
        - vielleicht rausschmeißen
    - Observer rausgeben (beim Dataset)
    - Frames + EM → gaze
    - Frames → gaze + EM (**Ziel**)
    - Frames + gaze → EM
    - Visualisierungen erstellen
        - Frames + raw gaze data (mit EM-labels)
        - Frames + avg gaze data (mit EM-labels)
    - Majority-vote
        - Saccades sehr kurz → vllt immer priorisieren
- 03.11.21
    - Dokumente teilen (Github issues, Google Doc, Notion Markdown exportieren)
    - Im Repository auch Zwischenstände einchecken
    - Averagen für Augenbewegungen problematisch?
        - für Kurven problematisch
        - Abstand zu mean berechnen → Große Abstände?
    - Nico: Lieber Hz beim Averagen nehmen - da Eye-Tracker möglicherweise länger läuft
    - png anstatt jpg nutzen wegen Kompression
    - Visualisierung von averages und Labels priorisieren
    - GazeCom Framerate überprüfen (Bei Yannic verschieden angezeigt)
    - ResNets nicht als Teil des Models, sondern Features vorher abspeichern
        - Features aus verschiedenen Layern nehmen
        - SqueezeNet?
        - Layers aus Anfang, Mitte, Ende
        - 2D, nicht 3D → temporale Komponente den RIMs überlassen
            - Bei 3D müssten Windows definiert werden und sichergestellt werden, dass
        - Räumliche Komponente muss erhalten bleiben
    - Server-Zugriff zum Trainieren klären
    - Embedding zwischenschalten falls Dimensionen zu groß werden
    - Plan für nächstes Meeting
        - Visualisierung von Averaging
        - Pre-processing von Features in ResNets planen
            - Auf Server ausführen?
        - Überlegen, wie Notizen/TODOs am besten geteilt werden können
- 10.11.21
    - Visualisierung von Labeldaten besprochen
    - Frames down-skalieren von 720x1280 (GazeCom)
    - Zu diskutieren: Nur letzten Output von Feature Pyramid oder Stack von Outputs verwenden?
    - Eye-tracking Daten für GazeCom stimmen nicht immer mit Video-Länge überein
        - koenigsstrasse/bumblebee keine 597 Frames
        - YFK_puppies.arff: Daten für 93 Frames fehlen, bei 97 anderen fehlen 1-5 Frames
            - Frage: Wurde Eye-Tracker zu spät angestellt oder zu früh abgeschaltet?
        - Lösung: Als Noise klassifizieren und in der Loss-Function verwerfen
    - Challenge: Loss-Funktion die dazu sorgt dass predictions nicht immer in der Mitte liegen
    - Nächster Schritt: Implementierung feature extraction
        - Feature-Pyramide mit RIM zunächst zusammenlassen, inference time testen
    - Server-Zugriff testen
- 10.11.21
    - Visualisierung von Labeldaten besprochen
    - Frames down-skalieren von 720x1280 (GazeCom)
    - Zu diskutieren: Nur letzten Output von Feature Pyramid oder Stack von Outputs verwenden?
    - Eye-tracking Daten für GazeCom stimmen nicht immer mit Video-Länge überein
        - koenigsstrasse/bumblebee keine 597 Frames
        - YFK_puppies.arff: Daten für 93 Frames fehlen, bei 97 anderen fehlen 1-5 Frames
            - Frage: Wurde Eye-Tracker zu spät angestellt oder zu früh abgeschaltet?
        - Lösung: Als Noise klassifizieren und in der Loss-Function verwerfen
    - Challenge: Loss-Funktion die dazu sorgt dass predictions nicht immer in der Mitte liegen
    - Nächster Schritt: Implementierung feature extraction
        - Feature-Pyramide mit RIM zunächst zusammenlassen, inference time testen
    - Server-Zugriff testen
- 17.11.21
    - 640x360px vielleicht noch zu groß
        - nach ImageNet orientieren (224x224)
            - könnte x gegen y angleichen, quasi normieren
            - menschliche Augenbewegungen vermutlich mehr auf der x-Achse
    - Stochastizität & Funktionssuche für später
    - Parallelisierung des Dataloaders überprüfen
        - Liegt möglicherweise an Windows und kein Problem auf Linux-Server
            - ssh-Verbindung einrichten (mit ProxyJump über alioth)
            - Conda + cuda einrichten
                - Cuda sagen nur eine GPU zu nutzen (am besten im Code)
                - Cuda Toolkit abgleichen mit Server-Version
    - Aggregation von RIM Outputs
        - Im Paper Dense-Layer, aber vermutlich besser ein Attention-Layer anzuhängen
    - Loss-Function
        - exclude noise phases from loss calculations
        - cross-entropy loss
            - möglicherweise weighted, damit Saccaden nicht übergangen werden
        - Zuerst Model von reinen Bilddaten auf gaze + EM-Phase predicten
        - Möglicherweise **Mean Squared Log-scaled Error Loss** benutzen ([https://stats.stackexchange.com/questions/261704/training-a-neural-network-for-regression-always-predicts-the-mean](https://stats.stackexchange.com/questions/261704/training-a-neural-network-for-regression-always-predicts-the-mean))
- 24.11.21
    - Normalisierung überprüfen
        - Visualisierung möglicherweise ohne Normalisierung
    - Kein Einfluss von Bilddaten in Predictions erkennbar
        - FPN gibt möglicherweise Noise aus
            - FPN Features plotten um zu testen, ob Bild-Features und Bewegungen ersichtlich sind
        - Overfitting auf einem bestimmtem Clip um Funktionsweise zu testen
            - Zunächst nur Loss minimieren
        - Rekurrenz entfernen um Einfluss zu testen (nur einen Frame)
    - Irgendwann teacher forcing implementieren
    - Beam search anstatt greedy first approach → längere, schönere Trajectories und weniger Verlass auf
    - Dataloader möglicherweise anpassen um State von letztem Clip zu laden
        - hidden states RIM
        - xy für teacher forcing
            - output als input (Label bzw. vorherige Prediction)
    - Gradient/Weights Update loggen
    - Feature Pyramid Features plotten
        - Tensor in Tensorboard loggen?
- 01.12.21
    - Nur für einen (zwei) Frame trainieren
        - langsam an mehr Frames rantasten
    - Normalisierung für Labels implementieren, Mitte als (0, 0) wählen
    - Loss ist sehr hoch - Sollte überprüft werden
    - Ausprobieren, die Top-Down Parameter einmal aus der Optmierung rausnehmen
    - RIM-weights sollten ebenfalls geloggt werden
    - Für RIM sind 3 Layer sehr viel, am besten am RIM-Paper ausrichten
    - Aggregation zu 2 Gaze Koordinaten überarbeiten
        - Am besten auch an Paper ausrichten
    - Falls Maßnahmen keine Verbesserung ergeben, einfach direkt auf Pixel-Werten lernen (ohne FPN)
